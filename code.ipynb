{"cells":[{"cell_type":"markdown","metadata":{"id":"aqrEnjvv-b3q"},"source":["## **Importing Libraries**\n","This code block is responsible for setting up the necessary environment and importing the required libraries for the project.\n","\n","1. It imports the necessary libraries for the project, including:\n","   - `os`: For operating system-related functions.\n","   - `math`, `numpy`, `tensorflow`, `matplotlib`, and `scipy`: For various mathematical and scientific computing operations.\n","   - `sklearn.metrics`: For performance evaluation metrics like the classification report.\n","   - `tensorflow.keras`: For the deep learning framework, including models, layers, data generators, optimizers, and loss functions.\n","   - `tensorflow.keras.applications`: For pre-trained models like ResNet50 and ResNet152.\n","\n","2. It sets the Keras backend to TensorFlow, which is the backend used for the project.\n","\n","This code block sets up the foundational components required for the rest of the project, including the necessary libraries and the Keras backend. It provides the essential building blocks for the subsequent data preparation, model training, and evaluation steps of the project."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6GmHH28J-b3t"},"outputs":[],"source":["# Import necessary libraries\n","import os\n","os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"  # Set the Keras backend to TensorFlow\n","import math, numpy as np, tensorflow as tf, matplotlib as mpl, matplotlib.pyplot as plt\n","from scipy.special import softmax\n","from sklearn.metrics import classification_report\n","from tensorflow.keras.models import Model, load_model\n","from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.utils import load_img, img_to_array, array_to_img\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import categorical_crossentropy\n","from tensorflow.keras.applications import ResNet50, ResNet152"]},{"cell_type":"markdown","metadata":{"id":"Xdu01Mb_-b3x"},"source":["## **Image and Layer Configuration**\n","\n","This code block sets the image size and the name of the last convolutional layer, which will be used in the project.\n","\n","1. `img_size = (224, 224)`: This line sets the image size to 224x224 pixels, which is a common input size for many deep learning models, especially those based on pre-trained architectures like ResNet.\n","\n","2. `last_conv_layer_name = \"conv5_block3_out\"`: This line sets the name of the last convolutional layer, which will be used in the Grad-CAM heatmap generation process. Grad-CAM (Gradient-weighted Class Activation Mapping) is a technique that visualizes the important regions of an image for a specific prediction, and it requires access to the activations of the last convolutional layer.\n","\n","This code block establishes the necessary parameters for the image data and the Grad-CAM heatmap generation, which are crucial for the project's model training and interpretation tasks."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"njZxWR5c-b3x"},"outputs":[],"source":["# Set image size and last convolutional layer name\n","img_size = (224, 224)  # Set the image size to 224x224 pixels\n","last_conv_layer_name = \"conv5_block3_out\"  # Set the name of the last convolutional layer"]},{"cell_type":"markdown","metadata":{"id":"JvMKjHCd-b3x"},"source":["## **Data Generator Setup**\n","\n","This code block sets up the data generators for the training, validation, and test sets, which will be used to load and preprocess the image data for the deep learning model.\n","\n","1. `train_val_data_generator = ImageDataGenerator(...)`: This line creates a data generator for the training and validation sets, applying various data augmentation techniques, such as rescaling, shearing, zooming, and horizontal flipping. The `validation_split=0.2` parameter reserves 20% of the data for the validation set.\n","\n","2. `test_data_generator = ImageDataGenerator(rescale=1./255)`: This line creates a data generator for the test set, only applying rescaling to the pixel values.\n","\n","3. `train_generator = train_val_data_generator.flow_from_directory(...)`: This line creates the training data generator by loading the images from the specified `'./image-net-data/training-set'` directory, setting the target size to 224x224 pixels, the batch size to 32, and the class mode to 'categorical'. The `subset='training'` parameter specifies that this generator should use the training subset of the data.\n","\n","4. `validation_generator = train_val_data_generator.flow_from_directory(...)`: This line creates the validation data generator using the same training and validation directory, but with the `subset='validation'` parameter to use the validation subset of the data.\n","\n","5. `test_generator = test_data_generator.flow_from_directory(...)`: This line creates the test data generator by loading the images from the specified `'./image-net-data/testing-set'` directory, with the same target size and batch size as the training and validation generators. The `class_mode='categorical'` and `shuffle=False` parameters ensure that the test set is not shuffled, allowing for accurate evaluation.\n","\n","This code block sets up the necessary data generators for the project, ensuring that the image data is properly loaded, preprocessed, and organized for the subsequent model training and evaluation steps."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CMHCEXgt-b3x"},"outputs":[],"source":["# Define data generators for training, validation, and testing\n","train_val_data_generator = ImageDataGenerator(rescale=1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=True, validation_split=0.2)  # Define the training and validation data generator\n","test_data_generator = ImageDataGenerator(rescale=1./255)  # Define the test data generator\n","\n","# Create generators for training, validation, and test sets\n","train_generator = train_val_data_generator.flow_from_directory('./image-net-data/training-set', target_size=(224, 224), batch_size=32, class_mode='categorical', subset='training')  # Create the training data generator\n","validation_generator = train_val_data_generator.flow_from_directory('./image-net-data/training-set', target_size=(224, 224), batch_size=32, class_mode='categorical', subset='validation')  # Create the validation data generator\n","test_generator = test_data_generator.flow_from_directory('./image-net-data/testing-set', target_size=(224, 224), batch_size=32, class_mode='categorical', shuffle=False)  # Create the test data generator"]},{"cell_type":"markdown","metadata":{"id":"8Oqd9-oC-b3y"},"source":["## **Class Index Verification and Tag-Index Mapping**\n","\n","This code block ensures that the class indices are consistent across the training, validation, and test data generators, and it creates mappings between the class tags and their corresponding indices.\n","\n","1. `assert train_generator.class_indices == test_generator.class_indices == validation_generator.class_indices`: This line verifies that the class indices (the mapping between class labels and their corresponding integer indices) are the same across the training, validation, and test data generators. This is an important check to ensure that the data is properly organized and that the class labels match across the different sets.\n","\n","2. `tag_to_idx = train_generator.class_indices`: This line gets the mapping of class tags (the actual class labels) to their corresponding indices from the training data generator and stores it in the `tag_to_idx` dictionary.\n","\n","3. `idx_to_tag = {v: k for k, v in tag_to_idx.items()}`: This line creates the inverse mapping, from indices to class tags, by iterating over the `tag_to_idx` dictionary and swapping the keys and values.\n","\n","These mappings between class tags and indices will be used later in the project, for example, when converting the predicted labels to their corresponding class names for reporting and visualization purposes."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G6_EyJJM-b3y"},"outputs":[],"source":["# Ensure that the class indices are the same across all generators\n","assert train_generator.class_indices == test_generator.class_indices == validation_generator.class_indices  # Verify that the class indices are the same\n","tag_to_idx = train_generator.class_indices  # Get the mapping of class tags to indices\n","idx_to_tag = {v: k for k, v in tag_to_idx.items()}  # Create the inverse mapping of indices to class tags"]},{"cell_type":"markdown","metadata":{"id":"aFUxNip3-b3y"},"source":["## **Loading Data into Memory**\n","\n","This code block loads the training, validation, and test data into memory, preparing it for the subsequent model training and evaluation steps.\n","\n","1. `train_set_images, train_set_labels = [], []`: These lines initialize empty lists to store the training set images and labels.\n","\n","2. `steps_per_epoch_train = train_generator.samples // train_generator.batch_size + (1 if train_generator.samples % train_generator.batch_size else 0)`: This line calculates the number of steps (batches) per training epoch, based on the total number of training samples and the batch size.\n","\n","3. `for _ in range(steps_per_epoch_train):`: This loop iterates through the training set, retrieving the next batch of images and labels using the `next(train_generator)` call, and appending them to the `train_set_images` and `train_set_labels` lists, respectively.\n","\n","4. The code then repeats a similar process for the validation and test sets, creating the `validation_set_images`, `validation_set_labels`, `test_set_images`, and `test_set_labels` lists.\n","\n","This code block ensures that the entire training, validation, and test datasets are loaded into memory, which is necessary for the model training and evaluation processes. By storing the data in these lists, the model can efficiently access the images and labels during training and testing."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SVKvdHHb-b3z"},"outputs":[],"source":["# Load training, validation, and test data into memory\n","train_set_images, train_set_labels = [], []  # Initialize the training set images and labels lists\n","steps_per_epoch_train = train_generator.samples // train_generator.batch_size + (1 if train_generator.samples % train_generator.batch_size else 0)  # Calculate the number of steps per training epoch\n","for _ in range(steps_per_epoch_train):  # Iterate through the training set\n","    images, labels = next(train_generator)  # Get the next batch of images and labels\n","    train_set_images.append(images)  # Append the images to the training set images list\n","    train_set_labels.append(labels)  # Append the labels to the training set labels list\n","\n","validation_set_images, validation_set_labels = [], []  # Initialize the validation set images and labels lists\n","steps_per_epoch_validation = validation_generator.samples // validation_generator.batch_size + (1 if validation_generator.samples % validation_generator.batch_size else 0)  # Calculate the number of steps per validation epoch\n","for _ in range(steps_per_epoch_validation):  # Iterate through the validation set\n","    images, labels = next(validation_generator)  # Get the next batch of images and labels\n","    validation_set_images.append(images)  # Append the images to the validation set images list\n","    validation_set_labels.append(labels)  # Append the labels to the validation set labels list\n","\n","test_set_images, test_set_labels = [], []  # Initialize the test set images and labels lists\n","steps_per_epoch_test = test_generator.samples // test_generator.batch_size + (1 if test_generator.samples % test_generator.batch_size else 0)  # Calculate the number of steps per test epoch\n","for _ in range(steps_per_epoch_test):  # Iterate through the test set\n","    images, labels = next(test_generator)  # Get the next batch of images and labels\n","    test_set_images.append(images)  # Append the images to the test set images list\n","    test_set_labels.append(labels)  # Append the labels to the test set labels list"]},{"cell_type":"markdown","metadata":{"id":"hZW1kCsz-b3z"},"source":["## **Data Dimension Verification**\n","\n","This code block verifies that the loaded training, validation, and test data have the expected dimensions and that the batches have the correct number of samples.\n","\n","1. `assert len(train_set_images) == len(train_set_labels)`: This line ensures that the number of training images and the number of training labels are the same, as they should be.\n","\n","2. `assert len(validation_set_images) == len(validation_set_labels)`: This line ensures that the number of validation images and the number of validation labels are the same.\n","\n","3. `assert len(test_set_images) == len(test_set_labels)`: This line ensures that the number of test images and the number of test labels are the same.\n","\n","4. `assert len(train_set_images[0]) == len(validation_set_images[0]) == len(test_set_images[0]) == len(train_set_labels[0]) == len(validation_set_labels[0]) == len(test_set_labels[0]) == 32`: This line verifies that each batch of data (training, validation, and test) has 32 samples, as specified in the data generator configuration.\n","\n","5. `print(len(test_set_images), len(train_set_images), len(validation_set_images))`: This line prints the lengths of the test, training, and validation sets, which can be useful for monitoring the data loading process.\n","\n","These assertions and the print statement ensure that the loaded data has the expected dimensions and that the batches have the correct number of samples. This is an important step to verify the integrity of the data before proceeding with the model training and evaluation."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FkgSamzq-b3z"},"outputs":[],"source":["# Ensure that the data has the expected dimensions\n","assert len(train_set_images) == len(train_set_labels)  # Verify that the training set images and labels have the same length\n","assert len(validation_set_images) == len(validation_set_labels)  # Verify that the validation set images and labels have the same length\n","assert len(test_set_images) == len(test_set_labels)  # Verify that the test set images and labels have the same length\n","assert len(train_set_images[0]) == len(validation_set_images[0]) == len(test_set_images[0]) == len(train_set_labels[0]) == len(validation_set_labels[0]) == len(test_set_labels[0]) == 32  # Verify that each batch has 32 samples\n","\n","# Print the lengths of the test, train, and validation sets\n","print(len(test_set_images), len(train_set_images), len(validation_set_images))  # Print the lengths of the test, train, and validation sets"]},{"cell_type":"markdown","metadata":{"id":"9difg5PE-b30"},"source":["## **Teacher Model Training and Evaluation**\n","\n","This code block is responsible for training and evaluating the teacher model, which is a larger and more complex model compared to the student model.\n","\n","1. `taecher_training = True`: This line sets a flag to determine whether the teacher model should be trained or if a pre-trained model should be loaded.\n","\n","2. `if taecher_training:`: This conditional block runs if the `taecher_training` flag is set to `True`.\n","\n","3. `base_teacher_model = ResNet152(...)`: This line loads the base ResNet152 model with pre-trained ImageNet weights, but without the top layer.\n","\n","4. `for layer in base_teacher_model.layers: layer.trainable = False`: This loop freezes the layers of the base model to prevent them from being trained.\n","\n","5. The code then adds a global average pooling layer and a dense layer with softmax activation to create the final teacher model.\n","\n","6. `teacher_model = Model(...)`: This line creates the teacher model and compiles it with the Adam optimizer, categorical cross-entropy loss, and accuracy metric.\n","\n","7. The code then trains the teacher model for 50 epochs, printing the training loss and accuracy for every 10 batches, and computing the validation loss and accuracy at the end of each epoch.\n","\n","8. `teacher_model.save('./models/teacher_model.h5')`: This line saves the trained teacher model to a file.\n","\n","9. `else: teacher_model = load_model('./models/teacher_model.h5')`: If the `taecher_training` flag is set to `False`, this block loads the pre-trained teacher model from the saved file.\n","\n","This code block establishes the teacher model, which is a crucial component of the knowledge distillation process. By training the teacher model on the ImageNet dataset and saving it, the student model can later be trained to mimic the teacher's performance and gradient-based explanations."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rAxTWLL5-b31"},"outputs":[],"source":["# Check if teacher training is enabled\n","taecher_training = True  # Set this flag to True to enable teacher training, False to load pre-trained model\n","\n","# If teacher training is enabled\n","if taecher_training:\n","    # Load the base ResNet152 model with ImageNet weights, without the top layer\n","    base_teacher_model = ResNet152(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n","\n","    # Freeze the layers of the base model to prevent them from being trained\n","    for layer in base_teacher_model.layers:\n","        layer.trainable = False\n","\n","    # Add a global average pooling layer and a dense layer with softmax activation\n","    x = base_teacher_model.output\n","    x = GlobalAveragePooling2D()(x)\n","    predictions = Dense(len(tag_to_idx), activation='softmax')(x)\n","\n","    # Create the teacher model and compile it\n","    teacher_model = Model(inputs=base_teacher_model.input, outputs=predictions)\n","    teacher_model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","    # Train the teacher model for 50 epochs\n","    epochs = 50\n","    for epoch in range(epochs):\n","        print(f\"Epoch {epoch+1}/{epochs}\")\n","        for batch, (images, labels) in enumerate(zip(train_set_images, train_set_labels)):\n","            with tf.GradientTape() as tape:\n","                preds = teacher_model(images, training=False)\n","                loss = categorical_crossentropy(labels, preds)\n","\n","            grads = tape.gradient(loss, teacher_model.trainable_variables)\n","            teacher_model.optimizer.apply_gradients(zip(grads, teacher_model.trainable_variables))\n","            accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(preds, axis=1), tf.argmax(labels, axis=1)), tf.float32))\n","\n","            if (batch + 1) % 10 == 0:\n","                print(f'Batch {batch + 1} - Training Loss: {round(float(loss.numpy().mean()), 2)} | Training Accuracy: {round(float(accuracy.numpy()), 2)}')\n","\n","        # Compute the validation loss and accuracy\n","        validation_loss, validation_accuracy = 0, 0\n","        for (validation_images, validation_labels) in zip(validation_set_images, validation_set_labels):\n","            validation_preds = teacher_model(validation_images, training=False)\n","            validation_loss += categorical_crossentropy(validation_labels, validation_preds).numpy().mean()\n","            validation_accuracy += float(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(validation_preds, axis=1), tf.argmax(validation_labels, axis=1)), tf.float32)).numpy())\n","\n","        validation_loss = round(validation_loss / len(validation_set_images), 2)\n","        validation_accuracy = round(validation_accuracy / len(validation_set_images), 2)\n","\n","        print(f\"Epoch {epoch + 1} Finished! Validation Loss: {validation_loss} | Validation Accuracy: {validation_accuracy}\")\n","\n","    # Save the trained teacher model\n","    teacher_model.save('./models/teacher_model.h5')\n","\n","# If teacher training is not enabled, load the pre-trained teacher model\n","else:\n","    teacher_model = load_model('./models/teacher_model.h5')"]},{"cell_type":"markdown","metadata":{"id":"IChmmR1x-b31"},"source":["## **Evaluating the Teacher Model on the Test Set**\n","\n","This code block is responsible for evaluating the performance of the teacher model on the test set.\n","\n","1. `y_test_true, y_test_pred = [], []`: These lines initialize two empty lists to store the true and predicted labels for the test set.\n","\n","2. `for (test_images, test_labels) in zip(test_set_images, test_set_labels):`: This loop iterates through the test set images and labels.\n","\n","3. `test_preds = teacher_model(test_images, training=False)`: This line makes predictions using the teacher model for the current batch of test images.\n","\n","4. `y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))`: This line appends the predicted labels (the index of the maximum value in the prediction vector) to the `y_test_pred` list.\n","\n","5. `y_test_true.extend(list(test_labels))`: This line appends the true labels to the `y_test_true` list.\n","\n","6. `y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]`: This line converts the predicted labels (indices) to their corresponding class tags using the `idx_to_tag` dictionary.\n","\n","7. `y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]`: This line converts the true labels (one-hot encoded) to their corresponding class tags using the `idx_to_tag` dictionary.\n","\n","8. `print(classification_report(y_true=y_test_true, y_pred=y_test_pred))`: This line prints the classification report for the test set, comparing the true and predicted labels.\n","\n","This code block evaluates the performance of the teacher model on the test set, providing valuable insights into the model's accuracy and ability to classify the test images correctly. The classification report generated at the end can be used to assess the teacher model's effectiveness and guide further model improvements or the training of the student model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G-QDvLh1-b31"},"outputs":[],"source":["# Initialize empty lists to store the true and predicted labels for the test set\n","y_test_true, y_test_pred = [], []\n","\n","# Iterate through the test set images and labels\n","for (test_images, test_labels) in zip(test_set_images, test_set_labels):\n","    # Get the predictions from the teacher model for the test images\n","    test_preds = teacher_model(test_images, training=False)\n","    # Append the predicted labels (index of the maximum value) to the y_test_pred list\n","    y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))\n","    # Append the true labels to the y_test_true list\n","    y_test_true.extend(list(test_labels))\n","\n","# Convert the predicted and true labels from indices to class tags\n","y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]\n","y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]\n","\n","# Print the classification report for the test set\n","print(classification_report(y_true=y_test_true, y_pred=y_test_pred))"]},{"cell_type":"markdown","metadata":{"id":"8kk_bXDi-b32"},"source":["## **Visualizing a Random Test Image and Its Predicted Label**\n","\n","This code block selects a random image from the test set, displays the image, and shows the predicted label for the image.\n","\n","1. `random_batch_number = np.random.choice(len(test_set_images))`: This line selects a random batch index from the test set images.\n","\n","2. `random_image_number = np.random.choice(len(test_set_images[random_batch_number]))`: This line selects a random image index within the chosen batch.\n","\n","3. `selected_image = np.expand_dims(test_set_images[random_batch_number][random_image_number], 0)`: This line retrieves the selected image from the test set and expands its dimensions to match the expected input shape of the model (batch size of 1).\n","\n","4. `selected_label = test_set_labels[random_batch_number][random_image_number]`: This line retrieves the true label for the selected image.\n","\n","5. `plt.imshow(selected_image.squeeze(0))`: This line displays the selected image.\n","\n","6. `plt.title(idx_to_tag[np.argmax(selected_label)])`: This line displays the predicted label for the selected image, using the `idx_to_tag` dictionary to convert the index to the corresponding class tag.\n","\n","7. `plt.show()`: This line shows the image and the predicted label.\n","\n","This code block is useful for quickly visualizing a randomly selected test image and its predicted label, which can provide insights into the model's performance and help identify any misclassifications or areas for improvement."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GSgvQ_01-b32"},"outputs":[],"source":["# Select a random batch and image index from the test set\n","random_batch_number = np.random.choice(len(test_set_images))\n","random_image_number = np.random.choice(len(test_set_images[random_batch_number]))\n","\n","# Retrieve the selected image and label\n","selected_image = np.expand_dims(test_set_images[random_batch_number][random_image_number], 0)\n","selected_label = test_set_labels[random_batch_number][random_image_number]\n","\n","# Display the selected image and its predicted label\n","plt.imshow(selected_image.squeeze(0))\n","plt.title(idx_to_tag[np.argmax(selected_label)])\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"PbfkqVB_-b32"},"source":["## **Grad-CAM Heatmap Generation and Visualization**\n","\n","This code block contains two functions: `make_gradcam_heatmap` and `display_gradcam`, which are responsible for generating and visualizing Grad-CAM (Gradient-weighted Class Activation Mapping) heatmaps.\n","\n","1. `make_gradcam_heatmap(img_array, model, last_conv_layer_name)`:\n","   - This function takes an input image, a model, and the name of the last convolutional layer as input.\n","   - It first creates a new model that maps the input image to the activations of the last convolutional layer and the output predictions.\n","   - It then computes the gradient of the top predicted class with respect to the activations of the last convolutional layer.\n","   - It calculates the weighted average of the gradients, where the weights are the mean intensity of the gradients over each feature map channel.\n","   - It multiplies the feature map activations by the weighted gradients and sums them to obtain the heatmap.\n","   - It normalizes the heatmap between 0 and 1 for visualization purposes.\n","   - Finally, it returns the normalized heatmap.\n","\n","2. `display_gradcam(img, heatmap, alpha=0.4)`:\n","   - This function takes an input image, the generated heatmap, and an optional alpha value (for superimposing the heatmap) as input.\n","   - It rescales the heatmap to the range 0-255.\n","   - It uses the 'jet' colormap to colorize the heatmap.\n","   - It superimposes the colorized heatmap on the original image.\n","   - It displays the resulting image.\n","\n","These functions are used to generate and visualize the Grad-CAM heatmaps, which highlight the important regions of an image that contribute the most to the model's predictions. This technique provides valuable interpretability and explainability for the deep learning model."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EAX6xrjh-b33"},"outputs":[],"source":["def make_gradcam_heatmap(img_array, model, last_conv_layer_name):\n","    # First, we create a model that maps the input image to the activations of the last conv layer as well as the output predictions\n","    grad_model = Model(model.inputs, [model.get_layer(last_conv_layer_name).output, model.output])\n","\n","    # Then, we compute the gradient of the top predicted class for our input image with respect to the activations of the last conv layer\n","    with tf.GradientTape() as tape:\n","        last_conv_layer_output, preds = grad_model(img_array)\n","        pred_index = tf.argmax(preds[0])\n","        class_channel = preds[:, pred_index]\n","\n","    # This is the gradient of the output neuron (top predicted or chosen) with regard to the output feature map of the last conv layer\n","    grads = tape.gradient(class_channel, last_conv_layer_output)\n","\n","    # This is a vector where each entry is the mean intensity of the gradient over a specific feature map channel\n","    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n","\n","    # We multiply each channel in the feature map array by \"how important this channel is\" with regard to the top predicted class then sum all the channels to obtain the heatmap\n","    last_conv_layer_output = last_conv_layer_output[0]\n","    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n","    heatmap = tf.squeeze(heatmap)\n","\n","    # For visualization purpose, we will also normalize the heatmap between 0 & 1\n","    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n","    return heatmap.numpy()\n","\n","def display_gradcam(img, heatmap, alpha=0.4):\n","    # Load the original image\n","    # img = load_img(img_path)\n","    # img = img_to_array(img)\n","    img = img.squeeze(0) * 255\n","    # Rescale heatmap to a range 0-255\n","    heatmap = np.uint8(255 * heatmap)\n","\n","    # Use jet colormap to colorize heatmap\n","    jet = mpl.colormaps[\"jet\"]\n","\n","    # Use RGB values of the colormap\n","    jet_colors = jet(np.arange(256))[:, :3]\n","    jet_heatmap = jet_colors[heatmap]\n","\n","    # Create an image with RGB colorized heatmap\n","    jet_heatmap = array_to_img(jet_heatmap)\n","    jet_heatmap = jet_heatmap.resize((img.shape[1], img.shape[0]))\n","    jet_heatmap = img_to_array(jet_heatmap)\n","\n","    # Superimpose the heatmap on original image\n","    superimposed_img = jet_heatmap * alpha + img\n","    superimposed_img = array_to_img(superimposed_img)\n","\n","    # Display Grad CAM\n","    plt.imshow(superimposed_img)\n","\n","    return None"]},{"cell_type":"markdown","metadata":{"id":"bDOQN8TT-b33"},"source":["## **Visualizing Predictions and Grad-CAM for a Selected Test Image**\n","\n","This code block visualizes the predictions and Grad-CAM heatmap for a selected test image using the teacher model.\n","\n","1. `plt.imshow(selected_image.squeeze(0))`: This line displays the selected test image.\n","\n","2. `teacher_model.layers[-1].activation = None`: This line removes the softmax activation from the last layer of the teacher model. This is necessary to visualize the raw predictions without the softmax function applied.\n","\n","3. `preds = softmax(teacher_model.predict(selected_image))`: This line makes a prediction using the teacher model for the selected image and applies the softmax function to the output to obtain the probability distribution.\n","\n","4. `print(preds, idx_to_tag[np.argmax(preds)])`: This line prints the predicted probabilities and the class tag of the top predicted class, using the `idx_to_tag` dictionary to map the index to the corresponding class label.\n","\n","5. `heatmap = make_gradcam_heatmap(selected_image, teacher_model, last_conv_layer_name)`: This line generates the Grad-CAM heatmap for the selected image using the `make_gradcam_heatmap` function and the teacher model.\n","\n","6. `plt.matshow(heatmap)`: This line displays the Grad-CAM heatmap.\n","\n","7. `plt.show()`: This line shows the displayed plots.\n","\n","8. `display_gradcam(selected_image, heatmap)`: This line displays the Grad-CAM visualization, which superimposes the heatmap on the original image.\n","\n","This code block provides a way to visualize the predictions and the Grad-CAM heatmap for a selected test image using the teacher model. This can be useful for interpreting the model's decision-making process and identifying the important regions of the image that contribute to the prediction."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UhmA1MgN-b33"},"outputs":[],"source":["# Display the selected image\n","plt.imshow(selected_image.squeeze(0))\n","\n","# Remove last layer's softmax\n","teacher_model.layers[-1].activation = None\n","\n","# Print what the top predicted class is\n","preds = softmax(teacher_model.predict(selected_image))\n","print(preds, idx_to_tag[np.argmax(preds)])\n","\n","# Generate class activation heatmap\n","heatmap = make_gradcam_heatmap(selected_image, teacher_model, last_conv_layer_name)\n","\n","# Display heatmap\n","plt.matshow(heatmap)\n","plt.show()\n","\n","# Display the Grad-CAM visualization\n","display_gradcam(selected_image, heatmap)"]},{"cell_type":"markdown","metadata":{"id":"aUw-E9H5-b34"},"source":["## **Knowledge Distillation Loss Calculation**\n","\n","This code block contains two functions: `soft_labels` and `distillation_loss`, which are integral to the knowledge distillation process where a smaller student model is trained to emulate the behavior of a larger teacher model.\n","\n","1. `soft_labels(logits, temperature)`:\n","   - This function is designed to soften the logits (the vector of raw predictions that a classification model generates) produced by the teacher model.\n","   - It takes the logits and a temperature parameter as inputs. The temperature controls the smoothness of the probabilities.\n","   - By applying the softmax function with temperature scaling to the logits, it generates a softer probability distribution over the classes.\n","   - The resulting soft labels are used to guide the student model during training, providing information about the relative probabilities of incorrect classes.\n","\n","2. `distillation_loss(y_true, y_pred, y_soft, temperature)`:\n","   - This function calculates the distillation loss, which is a composite loss function used during the training of the student model.\n","   - It takes the true labels (`y_true`), the student model's predictions (`y_pred`), the soft labels from the teacher model (`y_soft`), and the temperature as inputs.\n","   - The function computes two types of losses: the hard loss (`loss_hard`) and the soft loss (`loss_soft`).\n","   - The hard loss is the categorical cross-entropy between the true labels and the student model's predictions, reflecting the accuracy of the student model on the actual task.\n","   - The soft loss is the categorical cross-entropy between the soft labels from the teacher model and the softened predictions of the student model, encouraging the student to mimic the teacher's output distribution.\n","   - The total distillation loss is the sum of the hard and soft losses, and it is used to optimize the student model's parameters.\n","\n","These functions are crucial for implementing knowledge distillation, allowing the student model to learn both from the ground truth and the additional insights provided by the teacher model's soft labels. This approach can lead to improved performance of the student model, as it leverages the rich information contained in the teacher model's predictions."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HEhnivIw-b34"},"outputs":[],"source":["def soft_labels(logits, temperature):\n","    \"\"\"\n","    Description: Soften the output logits of the teacher model.\n","    \"\"\"\n","    # Apply the softmax function to the scaled logits. The temperature parameter\n","    # controls the softness of the probability distribution. A higher temperature\n","    # results in a softer distribution (i.e., less confident predictions).\n","    return tf.nn.softmax(logits / temperature)\n","\n","def distillation_loss(y_true, y_pred, y_soft, temperature):\n","    \"\"\"\n","    Description: Calculate the distillation loss.\n","    \"\"\"\n","    # Calculate the 'hard' loss using the true labels and the predictions of the student model.\n","    # This part of the loss ensures the student model learns the correct class predictions.\n","    loss_hard = categorical_crossentropy(y_true, y_pred)\n","\n","    # Calculate the 'soft' loss using the soft labels from the teacher model and the softened\n","    # predictions of the student model. The temperature is used again to soften the student's\n","    # predictions. This part of the loss helps the student model to approximate the teacher's\n","    # probability distribution.\n","    loss_soft = categorical_crossentropy(y_soft, tf.nn.softmax(y_pred / temperature))\n","\n","    # The total distillation loss is the sum of the hard and soft losses. This combined loss\n","    # is used to train the student model not just to predict the correct classes, but also to\n","    # produce similar probability distributions to the teacher model.\n","    return loss_hard + loss_soft"]},{"cell_type":"markdown","metadata":{"id":"Z78d-cQC-b34"},"source":["## **Student Model Architecture Definition**\n","\n","This code block is responsible for defining the architecture of the student model, which is a smaller neural network that will be trained using knowledge distillation from a larger teacher model.\n","The code defines a student model based on the ResNet50 architecture, which is a popular convolutional neural network known for its performance on image classification tasks. The model is adapted for the specific dataset by setting the input shape and replacing the top layer with a new dense layer that has as many units as there are classes in the dataset (`len(tag_to_idx)`). The softmax activation function ensures that the output can be interpreted as a probability distribution over the classes. This student model will later be trained using the soft labels and potentially the Grad-CAM heatmaps generated by the teacher model to improve its performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Lua2gbBR-b34"},"outputs":[],"source":["# Initialize a ResNet50 model with random weights and without the top classification layer.\n","# The input shape is set for images of size 224x224 with 3 color channels (RGB).\n","base_student_model = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n","\n","# Retrieve the output of the last layer of the base student model.\n","x = base_student_model.output\n","\n","# Apply global average pooling to the output features of the base model.\n","# This operation will average out the spatial dimensions, resulting in a single\n","# 1D feature vector per image.\n","x = GlobalAveragePooling2D()(x)\n","\n","# Add a dense (fully connected) layer with a number of units equal to the number of classes\n","# in the dataset (denoted by `len(tag_to_idx)`). The softmax activation function is used\n","# to produce a probability distribution over the class labels.\n","predictions = Dense(len(tag_to_idx), activation='softmax')(x)"]},{"cell_type":"markdown","metadata":{"id":"vYXkickq-b34"},"source":["## **Student Model Compilation**\n","\n","This code block is focused on finalizing the student model's architecture by specifying its inputs and outputs, and preparing it for training by compiling it with an optimizer, loss function, and evaluation metrics.\n","\n","The `Model` function from Keras is used to create a new model instance (`student_model`) that takes the input from the base ResNet50 model (`base_student_model.input`) and produces the output from the dense softmax layer (`predictions`). The model is then compiled with the Adam optimizer, which is a popular choice for training deep learning models due to its efficiency and adaptive learning rate capabilities. The learning rate is set to 0.01, which determines how much the model's weights are updated during training. The loss function used is categorical crossentropy, which is standard for classification problems where each instance belongs to exactly one class. The model's performance will be evaluated based on its accuracy on the training data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"u9ZNjNju-b35"},"outputs":[],"source":["# Define the student model by specifying the input layer of the base model and the newly added output layer.\n","student_model = Model(inputs=base_student_model.input, outputs=predictions)\n","\n","# Compile the student model by setting the optimizer, loss function, and metrics for training.\n","# Adam optimizer is used with a learning rate of 0.01.\n","# The loss function is categorical crossentropy, which is suitable for multi-class classification tasks.\n","# The model's performance is evaluated based on accuracy.\n","student_model.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"gZbt201c-b35"},"source":["## **Student Model Training with Distillation**\n","\n","This code block outlines the process of training the student model using knowledge distillation. It involves iterating over the dataset for a specified number of epochs, using both the hard labels and the soft labels generated by the teacher model to calculate the distillation loss. The student model's weights are updated based on this loss, and its performance is evaluated on both the training and validation sets.\n","\n","- The training process is set to run for a total of 10 epochs.\n","- A temperature of 5.0 is used to soften the probabilities in the soft labels generated by the teacher model.\n","- An empty list is initialized to store the soft labels for the training set.\n","- The training loop starts, iterating over each epoch and each batch of images and labels.\n","- For the first epoch, the teacher model's predictions are obtained, softened, and stored in `train_set_soft_labels`.\n","- For subsequent epochs, the stored soft labels are reused.\n","- The `distillation_loss` function is called to compute the loss for the student model, which includes both the hard and soft label components.\n","- Gradients are calculated with respect to the student model's trainable variables, and the optimizer is used to update the weights.\n","- Training accuracy is computed and printed every 10 batches.\n","- After each epoch, the model is evaluated on the validation set, and the validation loss and accuracy are calculated and printed.\n","- Finally, the trained student model is saved to the file system."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mRkT13qG-b35"},"outputs":[],"source":["# Set the number of epochs for training and the temperature for softening probabilities.\n","epochs = 10\n","temperature = 5.0\n","\n","# Initialize a list to store the soft labels for the training set.\n","train_set_soft_labels = []\n","\n","# Start the training loop over the specified number of epochs.\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","\n","    # Iterate over each batch of images and labels in the training set.\n","    for batch, (images, labels) in enumerate(zip(train_set_images, train_set_labels)):\n","\n","        # Record operations for automatic differentiation.\n","        with tf.GradientTape() as tape:\n","            # Obtain predictions from the student model.\n","            preds_student = student_model(images, training=True)\n","\n","            # During the first epoch, generate and store soft labels from the teacher model.\n","            if epoch == 0:\n","                preds_teacher = teacher_model(images, training=False)\n","                soft_labels_teacher = soft_labels(preds_teacher, temperature)\n","                train_set_soft_labels.append(soft_labels_teacher)\n","            else:\n","                # For subsequent epochs, reuse the stored soft labels.\n","                soft_labels_teacher = train_set_soft_labels[batch]\n","\n","            # Compute the distillation loss using both hard and soft labels.\n","            loss = distillation_loss(labels, preds_student, soft_labels_teacher, temperature)\n","\n","        # Calculate gradients of the loss with respect to the model's trainable variables.\n","        grads = tape.gradient(loss, student_model.trainable_variables)\n","        # Apply the gradients to update the model's weights.\n","        student_model.optimizer.apply_gradients(zip(grads, student_model.trainable_variables))\n","        # Calculate and print the training accuracy every 10 batches.\n","        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(preds_student, axis=1), tf.argmax(labels, axis=1)), tf.float32))\n","\n","        if (batch + 1) % 10 == 0:\n","            print(f'Batch {batch + 1} - Training Loss: {round(float(loss.numpy().mean()), 2)} | Training Accuracy: {round(float(accuracy.numpy()), 2)}')\n","\n","    # Initialize variables to accumulate validation loss and accuracy.\n","    validation_loss, validation_accuracy = 0, 0\n","    # Evaluate the model on the validation set.\n","    for (validation_images, validation_labels) in zip(validation_set_images, validation_set_labels):\n","        validation_preds = student_model(validation_images, training=False)\n","        validation_loss += categorical_crossentropy(validation_labels, validation_preds).numpy().mean()\n","        validation_accuracy += float(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(validation_preds, axis=1), tf.argmax(validation_labels, axis=1)), tf.float32)).numpy())\n","\n","    # Calculate the average validation loss and accuracy.\n","    validation_loss = round(validation_loss / len(validation_set_images), 2)\n","    validation_accuracy = round(validation_accuracy / len(validation_set_images), 2)\n","\n","    # Print the validation results for the current epoch.\n","    print(f\"Epoch {epoch + 1} Finished! Validation Loss: {validation_loss} | Validation Accuracy: {validation_accuracy}\")\n","\n","# Save the trained student model to the file system.\n","student_model.save('./models/student_model.h5')"]},{"cell_type":"markdown","metadata":{"id":"agacbsju-b36"},"source":["## **Evaluating the Student Model on the Test Set**\n","\n","This code block is responsible for evaluating the performance of the student model on the test set.\n","\n","1. `y_test_true, y_test_pred = [], []`: These lines initialize two empty lists to store the true and predicted labels for the test set.\n","\n","2. `for (test_images, test_labels) in zip(test_set_images, test_set_labels):`: This loop iterates through the test set images and labels.\n","\n","3. `test_preds = student_model(test_images, training=False)`: This line makes predictions using the student model for the current batch of test images.\n","\n","4. `y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))`: This line appends the predicted labels (the index of the maximum value in the prediction vector) to the `y_test_pred` list.\n","\n","5. `y_test_true.extend(list(test_labels))`: This line appends the true labels to the `y_test_true` list.\n","\n","6. `y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]`: This line converts the predicted labels (indices) to their corresponding class tags using the `idx_to_tag` dictionary.\n","\n","7. `y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]`: This line converts the true labels (one-hot encoded) to their corresponding class tags using the `idx_to_tag` dictionary.\n","\n","8. `print(classification_report(y_true=y_test_true, y_pred=y_test_pred))`: This line prints the classification report for the test set, comparing the true and predicted labels.\n","\n","This code block evaluates the performance of the student model on the test set, providing valuable insights into the model's accuracy and ability to classify the test images correctly. The classification report generated at the end can be used to assess the student model's effectiveness and guide further model improvements."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"127VzSuL-b36"},"outputs":[],"source":["# Initialize empty lists to store the true and predicted labels for the test set\n","y_test_true, y_test_pred = [], []\n","\n","# Iterate through the test set images and labels\n","for (test_images, test_labels) in zip(test_set_images, test_set_labels):\n","    # Get the predictions from the student model for the test images\n","    test_preds = student_model(test_images, training=False)\n","    # Append the predicted labels (index of the maximum value) to the y_test_pred list\n","    y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))\n","    # Append the true labels to the y_test_true list\n","    y_test_true.extend(list(test_labels))\n","\n","# Convert the predicted and true labels from indices to class tags\n","y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]\n","y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]\n","\n","# Print the classification report for the test set\n","print(classification_report(y_true=y_test_true, y_pred=y_test_pred))"]},{"cell_type":"markdown","metadata":{"id":"ShLcJ4ep-b36"},"source":["## **Visualizing Predictions and Grad-CAM for a Selected Test Image using the Student Model**\n","\n","This code block visualizes the predictions and Grad-CAM heatmap for a selected test image using the student model.\n","\n","1. `plt.imshow(selected_image.squeeze(0))`: This line displays the selected test image.\n","\n","2. `student_model.layers[-1].activation = None`: This line removes the softmax activation from the last layer of the student model. This is necessary to visualize the raw predictions without the softmax function applied.\n","\n","3. `preds = tf.nn.softmax(student_model.predict(selected_image))`: This line makes a prediction using the student model for the selected image and applies the softmax function to the output to obtain the probability distribution.\n","\n","4. `print(preds, idx_to_tag[np.argmax(preds)])`: This line prints the predicted probabilities and the class tag of the top predicted class, using the `idx_to_tag` dictionary to map the index to the corresponding class label.\n","\n","5. `heatmap = make_gradcam_heatmap(selected_image, student_model, last_conv_layer_name)`: This line generates the Grad-CAM heatmap for the selected image using the `make_gradcam_heatmap` function and the student model.\n","\n","6. `plt.matshow(heatmap)`: This line displays the Grad-CAM heatmap.\n","\n","7. `plt.show()`: This line shows the displayed plots.\n","\n","8. `display_gradcam(selected_image, heatmap)`: This line displays the Grad-CAM visualization, which superimposes the heatmap on the original image.\n","\n","This code block provides a way to visualize the predictions and the Grad-CAM heatmap for a selected test image using the student model. This can be useful for interpreting the student model's decision-making process and identifying the important regions of the image that contribute to the prediction. It allows for a direct comparison between the teacher and student models' interpretability and performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CiGIYw4e-b37"},"outputs":[],"source":["# Display the selected image\n","plt.imshow(selected_image.squeeze(0))\n","\n","# Remove the softmax activation from the last layer of the student model\n","student_model.layers[-1].activation = None\n","\n","# Get the predictions from the student model for the selected image\n","preds = tf.nn.softmax(student_model.predict(selected_image))\n","\n","# Print the top predicted class and its probability\n","print(preds, idx_to_tag[np.argmax(preds)])\n","\n","# Generate the Grad-CAM heatmap for the selected image using the student model\n","heatmap = make_gradcam_heatmap(selected_image, student_model, last_conv_layer_name)\n","\n","# Display the Grad-CAM heatmap\n","plt.matshow(heatmap)\n","plt.show()\n","\n","# Display the Grad-CAM visualization for the selected image\n","display_gradcam(selected_image, heatmap)"]},{"cell_type":"markdown","metadata":{"id":"uN8IzXce-b37"},"source":["## **Wasserstein Distance Computation for 2D Probability Distributions**\n","\n","This code block defines a function called `wasserstein_distance_2d` that computes the Wasserstein distance between two sets of 2D probability distributions.\n","\n","1. `def wasserstein_distance_2d(ps, qs):`: This line defines the function, which takes two arguments: `ps` and `qs`, both of which are lists of 2D probability distributions.\n","\n","2. `assert len(ps) == len(qs):`: This line ensures that the number of elements in `ps` and `qs` are the same, as the Wasserstein distance can only be computed when the distributions have the same number of elements.\n","\n","3. `wasserstein_dist = 0:`: This line initializes the Wasserstein distance to 0, which will be accumulated throughout the computation.\n","\n","4. `for p, q in zip(ps, qs):`: This loop iterates through the corresponding elements in `ps` and `qs`.\n","\n","5. `p_flat = tf.reshape(p, [-1])` and `q_flat = tf.reshape(q, [-1]):`: These lines flatten the 2D probability distributions into 1D tensors.\n","\n","6. `p_flat /= tf.reduce_sum(p_flat)` and `q_flat /= tf.reduce_sum(q_flat):`: These lines normalize the flattened tensors to ensure that they represent valid probability distributions.\n","\n","7. `cdf_p = tf.cumsum(p_flat)` and `cdf_q = tf.cumsum(q_flat):`: These lines compute the cumulative distribution functions (CDFs) of the normalized probability distributions.\n","\n","8. `wasserstein_dist += tf.reduce_sum(tf.abs(cdf_p - cdf_q)):`: This line computes the Wasserstein distance between the CDFs of the two probability distributions and adds it to the running total.\n","\n","9. `return wasserstein_dist / len(ps):`: Finally, this line returns the average Wasserstein distance across all the pairs of probability distributions.\n","\n","The Wasserstein distance is a useful metric for comparing two probability distributions, as it takes into account the underlying structure of the distributions, rather than just the difference between individual elements. In the context of this project, the Wasserstein distance is used to compare the Grad-CAM heatmaps generated by the teacher and student models, providing a way to measure the similarity of the explanations provided by the two models."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"148c2VLa-b37"},"outputs":[],"source":["def wasserstein_distance_2d(ps, qs):\n","    # Ensure that the number of elements in ps and qs are the same\n","    assert len(ps) == len(qs)\n","\n","    # Initialize the Wasserstein distance\n","    wasserstein_dist = 0\n","\n","    # Iterate through the elements in ps and qs\n","    for p, q in zip(ps, qs):\n","        # Flatten the tensors\n","        p_flat = tf.reshape(p, [-1])\n","        q_flat = tf.reshape(q, [-1])\n","\n","        # Normalize the flattened tensors\n","        p_flat /= tf.reduce_sum(p_flat)\n","        q_flat /= tf.reduce_sum(q_flat)\n","\n","        # Compute the cumulative distribution functions (CDFs) of p and q\n","        cdf_p = tf.cumsum(p_flat)\n","        cdf_q = tf.cumsum(q_flat)\n","\n","        # Compute the Wasserstein distance between the CDFs\n","        wasserstein_dist += tf.reduce_sum(tf.abs(cdf_p - cdf_q))\n","\n","    # Return the average Wasserstein distance\n","    return wasserstein_dist / len(ps)"]},{"cell_type":"markdown","metadata":{"id":"qsyLkFRc-b37"},"source":["## **Student Model Creation and Compilation**\n","\n","This code block is responsible for creating the base student model and the final student model, as well as compiling the student model for training.\n","\n","1. `base_student_model_2 = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))`: This line creates the base student model using the ResNet50 architecture, but without the top layer. The `weights=None` parameter indicates that the model will be trained from scratch, and the `input_shape` parameter specifies the input size of the images.\n","\n","2. `x = base_student_model_2.output`: This line extracts the output of the base student model.\n","\n","3. `x = GlobalAveragePooling2D()(x)`: This line adds a global average pooling layer to the model, which will reduce the spatial dimensions of the feature maps and provide a fixed-size output.\n","\n","4. `predictions = Dense(len(tag_to_idx), activation='softmax')(x)`: This line adds a dense layer with a softmax activation function to the model, which will output the class probabilities. The number of units in the dense layer is set to the length of the `tag_to_idx` dictionary, which represents the number of classes.\n","\n","5. `student_model_2 = Model(inputs=base_student_model_2.input, outputs=predictions)`: This line creates the final student model by defining the inputs (the base student model's input) and the outputs (the predictions from the previous layers).\n","\n","6. `student_model_2.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])`: This line compiles the student model with the Adam optimizer, categorical cross-entropy loss, and accuracy metric. The learning rate for the optimizer is set to 0.01.\n","\n","This code block sets up the student model architecture and prepares it for training. The base student model is created using the ResNet50 architecture, and additional layers are added to produce the final class probabilities. The compiled student model can now be trained using the specified optimizer, loss function, and evaluation metric."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TVzL9kms-b37"},"outputs":[],"source":["# Create the base student model with ResNet50 architecture, without the top layer\n","base_student_model_2 = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n","x = base_student_model_2.output\n","x = GlobalAveragePooling2D()(x)\n","predictions = Dense(len(tag_to_idx), activation='softmax')(x)\n","\n","# Create the student model and compile it\n","student_model_2 = Model(inputs=base_student_model_2.input, outputs=predictions)\n","student_model_2.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"]},{"cell_type":"markdown","metadata":{"id":"R_0DNlNd-b38"},"source":["## **Training the Student Model using Knowledge Distillation**\n","\n","This code block is responsible for training the student model using a knowledge distillation approach, where the student model is trained to mimic the performance and gradient-based explanations of the pre-trained teacher model.\n","\n","1. `epochs = 10`: This line sets the number of training epochs to 10.\n","2. `temperature = 5.0`: This line sets the temperature parameter used for softening the probabilities in the distillation loss.\n","3. `train_set_heatmaps = []`: This line initializes an empty list to store the Grad-CAM heatmaps of the teacher model for the training set.\n","4. `for epoch in range(epochs):`: This loop iterates through the training epochs.\n","5. `preds_student = student_model_2(images, training=True)`: This line gets the predictions from the student model for the current batch of training images.\n","6. `soft_labels_teacher = train_set_soft_labels[batch]`: This line retrieves the soft labels (probabilities) from the pre-trained teacher model for the current training batch.\n","7. `heatmaps_student = [make_gradcam_heatmap(...) for image in images]`: This line generates the Grad-CAM heatmaps for the student model's predictions on the current training batch.\n","8. `if epoch == 0: heatmaps_teacher = [...]; train_set_heatmaps.append(heatmaps_teacher)`: If it's the first epoch, this block generates the Grad-CAM heatmaps for the teacher model and stores them in the `train_set_heatmaps` list.\n","9. `loss = distillation_loss(...) + wasserstein_distance_2d(heatmaps_teacher, heatmaps_student)`: This line computes the combined loss, which includes the distillation loss (using the soft labels from the teacher) and the Wasserstein distance between the teacher and student Grad-CAM heatmaps.\n","10. `grads = tape.gradient(loss, student_model_2.trainable_variables)`: This line computes the gradients of the loss with respect to the student model's trainable variables.\n","11. `student_model_2.optimizer.apply_gradients(...)`: This line updates the student model's weights using the computed gradients and the Adam optimizer.\n","12. `accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(preds_student, axis=1), tf.argmax(labels, axis=1)), tf.float32))`: This line computes the training accuracy for the current batch.\n","13. `validation_loss, validation_accuracy = 0, 0`: These lines initialize the validation loss and accuracy.\n","14. `for (validation_images, validation_labels) in ...:`: This loop iterates through the validation set, computes the validation loss and accuracy, and updates the running totals.\n","15. `validation_loss = round(validation_loss / len(validation_set_images), 2)`: This line computes the average validation loss.\n","16. `validation_accuracy = round(validation_accuracy / len(validation_set_images), 2)`: This line computes the average validation accuracy.\n","17. `student_model_2.save('./models/student_model_2.h5')`: This line saves the trained student model to a file.\n","\n","This code block trains the student model using a knowledge distillation approach, where the student model is trained to not only match the labels predicted by the teacher model (soft labels), but also to mimic the teacher's gradient-based explanations (Grad-CAM heatmaps). The validation loss and accuracy are monitored during training, and the final student model is saved to a file."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KpR-hW2l-b4J"},"outputs":[],"source":["# Train the student model for 10 epochs\n","epochs = 10\n","temperature = 5.0  # Temperature used for softening the probabilities\n","train_set_heatmaps = []\n","for epoch in range(epochs):\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","    for batch, (images, labels) in enumerate(zip(train_set_images, train_set_labels)):\n","        with tf.GradientTape() as tape:\n","            # Get the predictions from the student model\n","            preds_student = student_model_2(images, training=True)\n","            # Get the soft labels from the teacher model\n","            soft_labels_teacher = train_set_soft_labels[batch]\n","\n","            # Generate the Grad-CAM heatmaps for the student and teacher models\n","            heatmaps_student = [make_gradcam_heatmap(np.expand_dims(image, 0), student_model_2, last_conv_layer_name) for image in images]\n","            if epoch == 0:\n","                heatmaps_teacher = [make_gradcam_heatmap(np.expand_dims(image, 0), teacher_model, last_conv_layer_name) for image in images]\n","                train_set_heatmaps.append(heatmaps_teacher)\n","            else:\n","                heatmaps_teacher = train_set_heatmaps[batch]\n","\n","            # Compute the distillation loss and Wasserstein distance\n","            loss = distillation_loss(labels, preds_student, soft_labels_teacher, temperature) + wasserstein_distance_2d(heatmaps_teacher, heatmaps_student)\n","\n","        # Update the student model's weights\n","        grads = tape.gradient(loss, student_model_2.trainable_variables)\n","        student_model_2.optimizer.apply_gradients(zip(grads, student_model_2.trainable_variables))\n","        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(preds_student, axis=1), tf.argmax(labels, axis=1)), tf.float32))\n","\n","        if (batch + 1) % 10 == 0:\n","            print(f'Batch {batch + 1} - Training Loss: {tf.reduce_mean(loss)} | Training Accuracy: {round(float(accuracy.numpy()), 2)}')\n","\n","    # Compute the validation loss and accuracy\n","    validation_loss, validation_accuracy = 0, 0\n","    for (validation_images, validation_labels) in zip(validation_set_images, validation_set_labels):\n","        validation_preds = student_model_2(validation_images, training=False)\n","        validation_loss += categorical_crossentropy(validation_labels, validation_preds).numpy().mean()\n","        validation_accuracy += float(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(validation_preds, axis=1), tf.argmax(validation_labels, axis=1)), tf.float32)).numpy())\n","\n","    validation_loss = round(validation_loss / len(validation_set_images), 2)\n","    validation_accuracy = round(validation_accuracy / len(validation_set_images), 2)\n","\n","    print(f\"Epoch {epoch + 1} Finished! Validation Loss: {validation_loss} | Validation Accuracy: {validation_accuracy}\")\n","\n","# Save the trained student model\n","student_model_2.save('./models/student_model_2.h5')"]},{"cell_type":"markdown","metadata":{"id":"kpoDIg_Z-b4J"},"source":["## **Evaluating the Student Model on the Test Set**\n","\n","This code block is responsible for evaluating the performance of the student model (student_model_2) on the test set.\n","\n","1. `y_test_true, y_test_pred = [], []`: These lines initialize two empty lists to store the true and predicted labels for the test set.\n","\n","2. `for (test_images, test_labels) in zip(test_set_images, test_set_labels):`: This loop iterates through the test set images and labels.\n","\n","3. `test_preds = student_model_2(test_images, training=False)`: This line makes predictions using the student model for the current batch of test images.\n","\n","4. `y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))`: This line appends the predicted labels (the index of the maximum value in the prediction vector) to the `y_test_pred` list.\n","\n","5. `y_test_true.extend(list(test_labels))`: This line appends the true labels to the `y_test_true` list.\n","\n","6. `y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]`: This line converts the predicted labels (indices) to their corresponding class tags using the `idx_to_tag` dictionary.\n","\n","7. `y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]`: This line converts the true labels (one-hot encoded) to their corresponding class tags using the `idx_to_tag` dictionary.\n","\n","8. `print(classification_report(y_true=y_test_true, y_pred=y_test_pred))`: This line prints the classification report for the test set, comparing the true and predicted labels.\n","\n","This code block evaluates the performance of the student model on the test set, providing valuable insights into the model's accuracy and ability to classify the test images correctly. The classification report generated at the end can be used to assess the student model's effectiveness and guide further model improvements or fine-tuning."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mlhVbAzV-b4K"},"outputs":[],"source":["# Initialize empty lists to store the true and predicted labels for the test set\n","y_test_true, y_test_pred = [], []\n","\n","# Iterate through the test set images and labels\n","for (test_images, test_labels) in zip(test_set_images, test_set_labels):\n","    # Get the predictions from the student model for the test images\n","    test_preds = student_model_2(test_images, training=False)\n","    # Append the predicted labels (index of the maximum value) to the y_test_pred list\n","    y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))\n","    # Append the true labels to the y_test_true list\n","    y_test_true.extend(list(test_labels))\n","\n","# Convert the predicted and true labels from indices to class tags\n","y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]\n","y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]\n","\n","# Print the classification report for the test set\n","print(classification_report(y_true=y_test_true, y_pred=y_test_pred))"]},{"cell_type":"markdown","metadata":{"id":"KHRGGnEn-b4K"},"source":["## **Visualizing Predictions and Grad-CAM for a Selected Test Image using the Student Model**\n","\n","This code block visualizes the predictions and Grad-CAM heatmap for a selected test image using the student model (student_model_2).\n","\n","1. `plt.imshow(selected_image.squeeze(0))`: This line displays the selected test image.\n","\n","2. `student_model_2.layers[-1].activation = None`: This line removes the softmax activation from the last layer of the student model. This is necessary to visualize the raw predictions without the softmax function applied.\n","\n","3. `preds = tf.nn.softmax(student_model_2.predict(selected_image))`: This line makes a prediction using the student model for the selected image and applies the softmax function to the output to obtain the probability distribution.\n","\n","4. `print(preds, idx_to_tag[np.argmax(preds)])`: This line prints the predicted probabilities and the class tag of the top predicted class, using the `idx_to_tag` dictionary to map the index to the corresponding class label.\n","\n","5. `heatmap = make_gradcam_heatmap(selected_image, student_model_2, last_conv_layer_name)`: This line generates the Grad-CAM heatmap for the selected image using the `make_gradcam_heatmap` function and the student model.\n","\n","6. `plt.matshow(heatmap)`: This line displays the Grad-CAM heatmap.\n","\n","7. `plt.show()`: This line shows the displayed plots.\n","\n","8. `display_gradcam(selected_image, heatmap)`: This line displays the Grad-CAM visualization, which superimposes the heatmap on the original image.\n","\n","This code block provides a way to visualize the predictions and the Grad-CAM heatmap for a selected test image using the student model. This can be useful for interpreting the student model's decision-making process and identifying the important regions of the image that contribute to the prediction. It allows for a direct comparison between the teacher and student models' interpretability and performance."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_sZPDuHx-b4K"},"outputs":[],"source":["# Display the selected image\n","plt.imshow(selected_image.squeeze(0))\n","\n","# Remove the softmax activation from the last layer of the student model\n","student_model_2.layers[-1].activation = None\n","\n","# Get the predictions from the student model for the selected image and apply softmax\n","preds = tf.nn.softmax(student_model_2.predict(selected_image))\n","\n","# Print the top predicted class and its probability\n","print(preds, idx_to_tag[np.argmax(preds)])\n","\n","# Generate the Grad-CAM heatmap for the selected image using the student model\n","heatmap = make_gradcam_heatmap(selected_image, student_model_2, last_conv_layer_name)\n","\n","# Display the Grad-CAM heatmap\n","plt.matshow(heatmap)\n","plt.show()\n","\n","# Display the Grad-CAM visualization for the selected image\n","display_gradcam(selected_image, heatmap)"]},{"cell_type":"markdown","source":["## **Configuration and Compilation of Student Model Trained on Hard Labels**\n","\n","This code block outlines the process of configuring a student model based on the ResNet50 architecture for training on hard labels, and preparing it for the training process.\n","\n","1. **Base Model Initialization**:\n","   ```python\n","   base_student_model_3 = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n","   ```\n","   A new instance of ResNet50 is created without pre-trained weights and without the fully connected top layers. The model is set to accept input images of size 224x224 pixels with 3 color channels.\n","\n","2. **Layer Freezing**:\n","   ```python\n","   for layer in base_student_model_3.layers:\n","       layer.trainable = False\n","   ```\n","   The trainable parameter of each layer in the base model is set to `False` to freeze the layers. This prevents the weights from being updated during training, which is a common approach when fine-tuning a model on a specific task.\n","\n","3. **Adding Custom Top Layers**:\n","   ```python\n","   x = base_student_model_3.output\n","   x = GlobalAveragePooling2D()(x)\n","   predictions = Dense(len(tag_to_idx), activation='softmax')(x)\n","   ```\n","   The output of the base model is passed through a GlobalAveragePooling2D layer to reduce dimensionality and parameters. A Dense layer with a softmax activation function is added to make final predictions. The number of units in the Dense layer corresponds to the number of classes, determined by the size of the `tag_to_idx` mapping.\n","\n","4. **Student Model Instantiation**:\n","   ```python\n","   student_model_3 = Model(inputs=base_student_model_3.input, outputs=predictions)\n","   ```\n","   A new model, `student_model_3`, is created using the Keras Model class, specifying the input and output layers.\n","\n","5. **Model Compilation**:\n","   ```python\n","   student_model_3.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n","   ```\n","   The student model is compiled with the Adam optimizer (with a learning rate of 0.01), a categorical crossentropy loss function suitable for multi-class classification with hard labels, and accuracy as the metric for evaluation."],"metadata":{"id":"qLOy7YpQktTL"}},{"cell_type":"code","source":["# Initialize the base model with the ResNet50 architecture, without pre-trained weights, and excluding the top layer.\n","base_student_model_3 = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n","\n","# Iterate through all the layers of the base model and set them to be non-trainable (weights will not be updated during training).\n","for layer in base_student_model_3.layers:\n","    layer.trainable = False\n","\n","# Get the output of the last layer of the base model.\n","x = base_student_model_3.output\n","\n","# Apply global average pooling to the output of the base model to reduce its dimensionality.\n","x = GlobalAveragePooling2D()(x)\n","\n","# Add a dense layer with a softmax activation function. The number of units equals the number of classes.\n","# This layer will output probability distribution over the classes.\n","predictions = Dense(len(tag_to_idx), activation='softmax')(x)\n","\n","# Create the final student model by specifying the input and output layers.\n","student_model_3 = Model(inputs=base_student_model_3.input, outputs=predictions)\n","\n","# Compile the student model with the Adam optimizer, a learning rate of 0.01, categorical crossentropy loss function,\n","# and accuracy metric for performance evaluation.\n","student_model_3.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"g35LuWMhmWiA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Training and Validation of the Student Model**\n","\n","This code block outlines the training and validation process for the student model over a specified number of epochs.\n","\n","1. **Setting Up Training Parameters**:\n","   - The variable `epochs` is set to 10, indicating the student model will undergo 10 full iterations (epochs) over the training dataset.\n","\n","2. **Training Loop**:\n","   - The `for` loop begins, iterating over the range of epochs, starting from 0 and going up to but not including `epochs`.\n","\n","3. **Epoch Progress Output**:\n","   - The `print` function outputs the progress of the training, showing the current epoch number out of the total epochs.\n","\n","4. **Batch Processing**:\n","   - Another `for` loop starts, iterating over each batch of images and labels from the training dataset. The `enumerate` function adds a counter (`batch`) to each iteration, and `zip` combines `train_set_images` with `train_set_labels` into pairs for processing.\n","\n","5. **Gradient Calculation**:\n","   - `tf.GradientTape` is used to record operations for automatic differentiation. This is essential for the backpropagation algorithm to work during the training process.\n","\n","6. **Model Predictions**:\n","   - Inside the `GradientTape` block, the student model (`student_model_3`) makes predictions on the training images with `training=False`, which is likely an error in the code since it should be set to `True` during training to enable dropout and other training-specific behaviors.\n","\n","7. **Loss Computation**:\n","   - The loss is calculated using `categorical_crossentropy`, which compares the predicted labels (`preds`) to the true labels (`labels`).\n","\n","8. **Backpropagation**:\n","   - Gradients of the loss with respect to the model's trainable variables are computed, and then these gradients are applied to the model's variables to minimize the loss using the `apply_gradients` method of the model's optimizer.\n","\n","9. **Accuracy Calculation**:\n","   - The accuracy for the current batch is calculated by comparing the predicted labels to the true labels, using the `tf.argmax` function to extract the predicted class indices and `tf.equal` to check for matches.\n","\n","10. **Training Status Output**:\n","   - Every 10 batches, the training loss and accuracy are printed to provide updates on the model's performance.\n","\n","11. **Validation Metrics Initialization**:\n","   - Before starting validation, `validation_loss` and `validation_accuracy` are set to 0 to prepare for accumulation.\n","\n","12. **Validation Loop**:\n","   - A loop starts over the validation dataset, where the student model makes predictions on the validation images, and the validation loss and accuracy are accumulated.\n","\n","13. **Average Validation Metrics**:\n","   - The total validation loss and accuracy are divided by the number of validation samples to calculate the average validation loss and accuracy.\n","\n","14. **Epoch Summary Output**:\n","   - At the end of each epoch, the average validation loss and accuracy are printed to summarize the model's performance on the validation dataset.\n","\n","15. **Model Saving**:\n","   - After training is complete, the student model is saved to a file (`student_model_3.h5`) for later use or analysis."],"metadata":{"id":"uSFx8WeFmfZr"}},{"cell_type":"code","source":["# Set the number of epochs for which the student model will be trained.\n","epochs = 10\n","\n","# Begin the training loop over the specified number of epochs.\n","for epoch in range(epochs):\n","    # Print the current epoch number.\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","\n","    # Iterate over each batch of images and labels from the training dataset.\n","    for batch, (images, labels) in enumerate(zip(train_set_images, train_set_labels)):\n","        # Record the operations for automatic differentiation using GradientTape.\n","        with tf.GradientTape() as tape:\n","            # Make predictions on the batch of images without enabling training-specific layers like dropout.\n","            preds = student_model_3(images, training=False)\n","            # Compute the loss by comparing the predicted labels to the true labels.\n","            loss = categorical_crossentropy(labels, preds)\n","\n","        # Calculate the gradients of the loss with respect to the model's trainable variables.\n","        grads = tape.gradient(loss, student_model_3.trainable_variables)\n","        # Apply the gradients to the model's variables to minimize the loss function.\n","        student_model_3.optimizer.apply_gradients(zip(grads, student_model_3.trainable_variables))\n","        # Calculate the batch's accuracy by comparing the predicted labels to the true labels.\n","        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(preds, axis=1), tf.argmax(labels, axis=1)), tf.float32))\n","\n","        # Print the training loss and accuracy every 10 batches.\n","        if (batch + 1) % 10 == 0:\n","            print(f'Batch {batch + 1} - Training Loss: {round(float(loss.numpy().mean()), 2)} | Training Accuracy: {round(float(accuracy.numpy()), 2)}')\n","\n","    # Initialize variables to accumulate validation loss and accuracy.\n","    validation_loss, validation_accuracy = 0, 0\n","    # Iterate over each batch of images and labels from the validation dataset.\n","    for (validation_images, validation_labels) in zip(validation_set_images, validation_set_labels):\n","        # Make predictions on the batch of validation images without enabling training-specific layers like dropout.\n","        validation_preds = student_model_3(validation_images, training=False)\n","        # Accumulate the validation loss.\n","        validation_loss += categorical_crossentropy(validation_labels, validation_preds).numpy().mean()\n","        # Accumulate the validation accuracy.\n","        validation_accuracy += float(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(validation_preds, axis=1), tf.argmax(validation_labels, axis=1)), tf.float32)).numpy())\n","\n","    # Calculate the average validation loss and accuracy over all validation batches.\n","    validation_loss = round(validation_loss / len(validation_set_images), 2)\n","    validation_accuracy = round(validation_accuracy / len(validation_set_images), 2)\n","\n","    # Print the final validation loss and accuracy for the current epoch.\n","    print(f\"Epoch {epoch + 1} Finished! Validation Loss: {validation_loss} | Validation Accuracy: {validation_accuracy}\")\n","\n","# Save the trained student model to a file for later use or analysis.\n","student_model_3.save('./models/student_model_3.h5')  # student hard"],"metadata":{"id":"GDu2DmnD_HRm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluating the Student Model on Test Set\n","\n","This code block is for evaluating the trained student model on a test dataset and generating a report that provides various classification metrics.\n","\n","1. **Initialize Lists for True and Predicted Labels**:\n","   ```python\n","   y_test_true, y_test_pred = [], []\n","   ```\n","   Two empty lists are initialized to store the true labels (`y_test_true`) and the predicted labels (`y_test_pred`) for the test dataset.\n","\n","2. **Iterate Over Test Dataset**:\n","   ```python\n","   for (test_images, test_labels) in zip(test_set_images, test_set_labels):\n","   ```\n","   The code iterates over the test images and labels, which are paired together using Python's `zip` function.\n","\n","3. **Make Predictions**:\n","   ```python\n","   test_preds = student_model_3(test_images, training=False)\n","   ```\n","   The student model (`student_model_3`) makes predictions on the test images with `training=False`. This ensures that the model uses its inference behavior, without any training-specific operations like dropout.\n","\n","4. **Store Predicted Labels**:\n","   ```python\n","   y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))\n","   ```\n","   The predicted probabilities (`test_preds`) are converted to class indices using the `tf.argmax` function, which selects the index with the highest probability (the predicted class). These indices are added to the `y_test_pred` list.\n","\n","5. **Store True Labels**:\n","   ```python\n","   y_test_true.extend(list(test_labels))\n","   ```\n","   The true labels from `test_labels` are added to the `y_test_true` list.\n","\n","6. **Convert Indices to Class Names**:\n","   ```python\n","   y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]\n","   y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]\n","   ```\n","   The predicted and true class indices are converted to their corresponding class names using the `idx_to_tag` dictionary. This dictionary maps numerical indices to class names (tags).\n","\n","7. **Print Classification Report**:\n","   ```python\n","   print(classification_report(y_true=y_test_true, y_pred=y_test_pred))\n","   ```\n","   A classification report is printed using scikit-learn's `classification_report` function. This report includes metrics such as precision, recall, f1-score, and support for each class, providing a detailed overview of the model's performance on the test dataset.\n","\n","Overall, this code block is used to assess the accuracy of the student model by comparing its predictions to the true labels on the test data and then providing a detailed classification analysis."],"metadata":{"id":"1wNSm7r3m3HT"}},{"cell_type":"code","source":["# Initialize lists to hold the true and predicted labels for the test set.\n","y_test_true, y_test_pred = [], []\n","\n","# Iterate over pairs of test images and labels.\n","for (test_images, test_labels) in zip(test_set_images, test_set_labels):\n","    # Make predictions using the student model on the test images with training set to False.\n","    test_preds = student_model_3(test_images, training=False)\n","    # Extend the prediction list with the predicted class indices obtained by taking the argmax of the predictions.\n","    y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))\n","    # Extend the true labels list with the actual labels from the test set.\n","    y_test_true.extend(list(test_labels))\n","\n","# Convert the list of predicted indices to their corresponding class names using the idx_to_tag mapping.\n","y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]\n","# Convert the list of true label indices to their corresponding class names using the idx_to_tag mapping.\n","y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]\n","\n","# Print the classification report comparing the true and predicted labels to evaluate the model's performance.\n","print(classification_report(y_true=y_test_true, y_pred=y_test_pred))"],"metadata":{"id":"sR3DoakV_IJF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Student Model Training with Soft Labels**\n","\n","This code block is designed to configure a student model to be trained using soft labels. Soft labels are a softened version of the original hard labels, typically provided by a teacher model's output logits, and they carry more information about the class probabilities.\n","\n","1. **Define Soft Labels Function**:\n","   ```python\n","   def soft_labels(logits, temperature):\n","   ```\n","   This function, `soft_labels`, takes logits from a teacher model and a temperature value to soften the logits.\n","\n","   ```python\n","   return tf.nn.softmax(logits / temperature)\n","   ```\n","   The logits are divided by the temperature to smooth the probability distribution, and then the softmax function is applied to obtain the soft labels.\n","\n","2. **Initialize Base Student Model**:\n","   ```python\n","   base_student_model_4 = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n","   ```\n","   A new instance of the ResNet50 model is created without pre-trained weights, excluding the top layer, and is set to accept input images of size 224x224 pixels with 3 color channels.\n","\n","3. **Add Custom Top Layers**:\n","   ```python\n","   x = base_student_model_4.output\n","   x = GlobalAveragePooling2D()(x)\n","   predictions = Dense(len(tag_to_idx), activation='softmax')(x)\n","   ```\n","   The output of the base model is passed through a GlobalAveragePooling2D layer, followed by a Dense layer with a softmax activation. The Dense layer is configured with a number of units equal to the number of classes, which is determined by the size of the `tag_to_idx` mapping.\n","\n","4. **Create Final Student Model**:\n","   ```python\n","   student_model_4 = Model(inputs=base_student_model_4.input, outputs=predictions)\n","   ```\n","   A new Keras Model instance, `student_model_4`, is created with the input layer from the base model and the custom top layers.\n","\n","5. **Compile the Student Model**:\n","   ```python\n","   student_model_4.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])\n","   ```\n","   The student model is compiled with the Adam optimizer and a learning rate of 0.01. The loss function is categorical crossentropy, which is suitable for classification tasks with soft labels, and accuracy is selected as the evaluation metric."],"metadata":{"id":"BJPX-K7annOm"}},{"cell_type":"code","source":["# Define a function to apply softmax with temperature scaling to logits, effectively creating soft labels.\n","def soft_labels(logits, temperature):\n","    \"\"\"\n","    Description: Soften the output logits of the teacher model.\n","    \"\"\"\n","    # Apply the softmax function to the scaled logits to obtain soft labels.\n","    return tf.nn.softmax(logits / temperature)\n","\n","# Initialize the base student model using the ResNet50 architecture without pre-trained weights and excluding the top layer.\n","base_student_model_4 = ResNet50(weights=None, include_top=False, input_shape=(224, 224, 3))\n","\n","# Retrieve the output from the last layer of the base student model.\n","x = base_student_model_4.output\n","# Apply global average pooling to the output to reduce its dimensionality.\n","x = GlobalAveragePooling2D()(x)\n","# Add a dense softmax layer to make predictions, with the number of units equal to the number of classes.\n","predictions = Dense(len(tag_to_idx), activation='softmax')(x)\n","\n","# Instantiate the final student model by specifying its input and output layers.\n","student_model_4 = Model(inputs=base_student_model_4.input, outputs=predictions)\n","# Compile the student model with the Adam optimizer, a learning rate of 0.01, and the categorical crossentropy loss function.\n","# The model will use accuracy as the metric for evaluation.\n","student_model_4.compile(optimizer=Adam(learning_rate=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"Nqd0mJ6PnsEY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## **Training Student Model with Softened Teacher Probabilities**\n","\n","This code block describes the training process of the student model using soft labels generated from the output of a teacher model, with temperature scaling applied to the probabilities.\n","\n","Of course, here's a detailed explanation for each line of the code:\n","\n","1. **Set Training Parameters**:\n","   - `epochs = 10`: This line sets the number of training cycles (epochs) that the student model will undergo to 10.\n","   - `temperature = 5.0`: This line sets the temperature value to 5.0. The temperature is a hyperparameter used to soften the output probabilities (logits) of the teacher model, making them smoother and more generalizable for distillation.\n","\n","2. **Prepare for Soft Label Storage**:\n","   - `train_set_soft_labels = []`: This line initializes an empty list that will later store the softened labels for the training set. These labels are generated from the teacher model's outputs.\n","\n","3. **Training Loop**:\n","   - `for epoch in range(epochs):`: This line starts a loop that will iterate over the set number of epochs.\n","   - `print(f\"Epoch {epoch+1}/{epochs}\")`: This line prints the current epoch number to the console, providing a progress update during training.\n","\n","4. **Batch Processing**:\n","   - `for batch, (images, labels) in enumerate(zip(train_set_images, train_set_labels)):`: This line starts a nested loop that iterates over each batch of images and labels in the training dataset.\n","\n","5. **Gradient Recording**:\n","   - `with tf.GradientTape() as tape:`: This line sets up a context manager that records the operations for automatic differentiation.\n","\n","6. **Make Predictions and Generate Soft Labels**:\n","   - `preds_student = student_model_4(images, training=True)`: Inside the gradient tape context, this line obtains predictions from the student model for the current batch of images.\n","   - `if epoch == 0:`: This conditional checks if it's the first epoch.\n","   - `preds_teacher = teacher_model(images, training=False)`: If it's the first epoch, this line gets predictions from the teacher model.\n","   - `soft_labels_teacher = soft_labels(preds_teacher, temperature)`: The teacher model's logits are softened using the `soft_labels` function and the set temperature.\n","   - `train_set_soft_labels.append(soft_labels_teacher)`: The softened labels are stored in the list for use in later epochs.\n","   - `else: soft_labels_teacher = train_set_soft_labels[batch]`: For subsequent epochs, the previously stored soft labels are retrieved.\n","\n","7. **Calculate Loss**:\n","   - `loss = categorical_crossentropy(soft_labels_teacher, tf.nn.softmax(preds_student / temperature))`: The loss is computed using the soft labels from the teacher and the softened predictions from the student model.\n","\n","8. **Backpropagation**:\n","   - `grads = tape.gradient(loss, student_model_4.trainable_variables)`: Gradients of the loss with respect to the student model's trainable variables are calculated.\n","   - `student_model_4.optimizer.apply_gradients(zip(grads, student_model_4.trainable_variables))`: The gradients are applied to the model's variables, updating them to minimize the loss.\n","\n","9. **Calculate Training Accuracy**:\n","   - `accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(preds_student, axis=1), tf.argmax(labels, axis=1)), tf.float32))`: The accuracy for the current batch is calculated by comparing the predicted and true labels.\n","\n","10. **Logging**:\n","   - `if (batch + 1) % 10 == 0:`: Every 10 batches, the conditional statement triggers logging.\n","   - `print(...)`: This line outputs the training loss and accuracy for the current batch to the console.\n","\n","11. **Validation Metrics Initialization**:\n","   - `validation_loss, validation_accuracy = 0, 0`: Before validation begins, the loss and accuracy are initialized to zero.\n","\n","12. **Validation Loop**:\n","   - `for (validation_images, validation_labels) in zip(validation_set_images, validation_set_labels):`: This line starts a loop over the validation dataset.\n","   - `validation_preds = student_model_4(validation_images, training=False)`: The student model makes predictions on the validation images.\n","   - `validation_loss += ...`: The validation loss is accumulated over all batches.\n","   - `validation_accuracy += ...`: The validation accuracy is accumulated over all batches.\n","\n","13. **Compute Average Validation Metrics**:\n","   - `validation_loss = ...`: The total validation loss is averaged over the number of validation samples.\n","   - `validation_accuracy = ...`: The total validation accuracy is averaged over the number of validation samples.\n","\n","14. **Epoch Summary**:\n","   - `print(f\"Epoch {epoch + 1} Finished! Validation Loss: {validation_loss} | Validation Accuracy: {validation_accuracy}\")`: At the end of each epoch, the average validation loss and accuracy are printed to summarize the model's performance on the validation set\n","\n","15. **Model Saving**:\n","   `student_model_4.save('./models/student_model_4.h5')`\n","\n","   The trained student model is saved to the specified file path, indicating that this model was trained using soft labels."],"metadata":{"id":"Na57AnhroscT"}},{"cell_type":"code","source":["# Set the number of epochs for training and the temperature for softening probabilities.\n","epochs = 10\n","temperature = 5.0 # temperature used for softening the probabilities\n","\n","# Initialize an empty list to store the soft labels for the training set.\n","train_set_soft_labels = []\n","\n","# Begin the training process for the specified number of epochs.\n","for epoch in range(epochs):\n","    # Print the current epoch number.\n","    print(f\"Epoch {epoch+1}/{epochs}\")\n","\n","    # Iterate over each batch of images and labels from the training dataset.\n","    for batch, (images, labels) in enumerate(zip(train_set_images, train_set_labels)):\n","        # Record the operations for automatic differentiation.\n","        with tf.GradientTape() as tape:\n","            # Make predictions on the training images using the student model.\n","            preds_student = student_model_4(images, training=True)\n","            # During the first epoch, generate and store soft labels using the teacher model's predictions.\n","            if epoch == 0:\n","                # Obtain predictions from the teacher model.\n","                preds_teacher = teacher_model(images, training=False)\n","                # Convert the teacher model's predictions to soft labels using the defined temperature.\n","                soft_labels_teacher = soft_labels(preds_teacher, temperature)\n","                # Store the soft labels for future epochs.\n","                train_set_soft_labels.append(soft_labels_teacher)\n","            else:\n","                # Retrieve the stored soft labels.\n","                soft_labels_teacher = train_set_soft_labels[batch]\n","\n","            # Calculate the loss using the soft labels and the softened student predictions.\n","            loss = categorical_crossentropy(soft_labels_teacher, tf.nn.softmax(preds_student / temperature))\n","\n","        # Compute the gradients of the loss with respect to the model's trainable variables.\n","        grads = tape.gradient(loss, student_model_4.trainable_variables)\n","        # Apply the gradients to the model's variables.\n","        student_model_4.optimizer.apply_gradients(zip(grads, student_model_4.trainable_variables))\n","        # Calculate the training accuracy for the current batch.\n","        accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(preds_student, axis=1), tf.argmax(labels, axis=1)), tf.float32))\n","\n","        # Print the training loss and accuracy for every 10 batches.\n","        if (batch + 1) % 10 == 0:\n","            print(f'Batch {batch + 1} - Training Loss: {round(float(loss.numpy().mean()), 2)} | Training Accuracy: {round(float(accuracy.numpy()), 2)}')\n","\n","    # Initialize variables for accumulating validation loss and accuracy.\n","    validation_loss, validation_accuracy = 0, 0\n","    # Iterate over each batch of images and labels from the validation set.\n","    for (validation_images, validation_labels) in zip(validation_set_images, validation_set_labels):\n","        # Make predictions on the validation images using the student model.\n","        validation_preds = student_model_4(validation_images, training=False)\n","        # Accumulate the validation loss.\n","        validation_loss += categorical_crossentropy(validation_labels, validation_preds).numpy().mean()\n","        # Accumulate the validation accuracy.\n","        validation_accuracy += float(tf.reduce_mean(tf.cast(tf.equal(tf.argmax(validation_preds, axis=1), tf.argmax(validation_labels, axis=1)), tf.float32)).numpy())\n","\n","    # Calculate the average validation loss and accuracy over all validation samples.\n","    validation_loss = round(validation_loss / len(validation_set_images), 2)\n","    validation_accuracy = round(validation_accuracy / len(validation_set_images), 2)\n","\n","    # Print the validation loss and accuracy at the end of the epoch.\n","    print(f\"Epoch {epoch + 1} Finished! Validation Loss: {validation_loss} | Validation Accuracy: {validation_accuracy}\")\n","\n","# Save the trained student model to the specified file path.\n","student_model_4.save('./models/student_model_4.h5') # student soft"],"metadata":{"id":"JQhLqELM_J8l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Evaluating the Student Model on Test Set\n","\n","1. **Initialize Lists for True and Predicted Labels**:\n","   ```python\n","   y_test_true, y_test_pred = [], []\n","   ```\n","   Two empty lists are created to store the true labels (`y_test_true`) and the predicted labels (`y_test_pred`) for the test dataset.\n","\n","2. **Iterate Over Test Dataset**:\n","   ```python\n","   for (test_images, test_labels) in zip(test_set_images, test_set_labels):\n","   ```\n","   The code iterates over the test images and labels, pairing them together using Python's `zip` function.\n","\n","3. **Make Predictions**:\n","   ```python\n","   test_preds = student_model_4(test_images, training=False)\n","   ```\n","   The student model (`student_model_4`) makes predictions on the test images with `training=False` to ensure it's in evaluation mode, not training mode.\n","\n","4. **Store Predicted Labels**:\n","   ```python\n","   y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))\n","   ```\n","   The predicted probabilities (`test_preds`) are converted to class indices by selecting the index of the highest probability for each prediction using `tf.argmax`. These indices are added to the `y_test_pred` list.\n","\n","5. **Store True Labels**:\n","   ```python\n","   y_test_true.extend(list(test_labels))\n","   ```\n","   The true labels from `test_labels` are added to the `y_test_true` list.\n","\n","6. **Convert Indices to Class Names (Predictions)**:\n","   ```python\n","   y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]\n","   ```\n","   The predicted class indices in `y_test_pred` are converted to their corresponding class names using the `idx_to_tag` dictionary. The `numpy()` method is called to convert the TensorFlow tensors to numpy arrays before looking up in the dictionary.\n","\n","7. **Convert Indices to Class Names (True Labels)**:\n","   ```python\n","   y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]\n","   ```\n","   The true class labels in `y_test_true` are converted to their corresponding class names using the `idx_to_tag` dictionary. Here, `np.argmax` is used to find the index of the true label since the labels are likely one-hot encoded.\n","\n","8. **Print Classification Report**:\n","   ```python\n","   print(classification_report(y_true=y_test_true, y_pred=y_test_pred))\n","   ```\n","   A classification report is printed using scikit-learn's `classification_report` function. This report includes metrics such as precision, recall, f1-score, and support for each class, providing a detailed overview of the model's performance on the test dataset."],"metadata":{"id":"3ia22xHLpbyP"}},{"cell_type":"code","source":["# Create empty lists to store the true and predicted labels for the test set.\n","y_test_true, y_test_pred = [], []\n","\n","# Loop through each pair of test images and labels.\n","for (test_images, test_labels) in zip(test_set_images, test_set_labels):\n","    # Obtain predictions from the student model for the current batch of test images.\n","    test_preds = student_model_4(test_images, training=False)\n","    # Extend the predicted labels list with the class indices predicted by the model.\n","    y_test_pred.extend(list(tf.argmax(test_preds, axis=1)))\n","    # Extend the true labels list with the actual labels from the test set.\n","    y_test_true.extend(list(test_labels))\n","\n","# Convert the list of predicted class indices to their corresponding class names using the idx_to_tag mapping.\n","y_test_pred = [idx_to_tag[x.numpy()] for x in y_test_pred]\n","# Convert the list of true label indices to their corresponding class names using the idx_to_tag mapping.\n","y_test_true = [idx_to_tag[np.argmax(x)] for x in y_test_true]\n","\n","# Print a classification report that compares the true and predicted labels, providing metrics like precision, recall, and F1-score.\n","print(classification_report(y_true=y_test_true, y_pred=y_test_pred))"],"metadata":{"id":"E-ZiwVfe_MX6"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"env_deeplearning","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}